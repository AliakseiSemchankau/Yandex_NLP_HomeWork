{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import linear_model\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readfile(filename):\n",
    "    with open(filename) as f:\n",
    "        content = f.readlines()\n",
    "    labels = []\n",
    "    texts = []\n",
    "    for line in content:\n",
    "        label, text = line.split('\\t')\n",
    "        if label == 'spam':\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "        text = text.split('\\n')[0]\n",
    "        texts.append(text)\n",
    "    return labels, texts\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5574\n",
      "5574\n"
     ]
    }
   ],
   "source": [
    "labels, texts = readfile('SMSSpamCollection.txt')\n",
    "print (len(labels))\n",
    "print (len(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5574, 8713)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=1)\n",
    "matrix = vectorizer.fit_transform(texts)\n",
    "print (matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.96598639  0.89855072  0.91549296  0.95833333  0.93706294  0.91304348\n",
      "  0.94444444  0.92753623  0.92198582  0.95104895]\n",
      "0.933348526858\n"
     ]
    }
   ],
   "source": [
    "lgclf = linear_model.LogisticRegression()\n",
    "scores = cross_val_score(lgclf, matrix, labels, cv=10, scoring='f1')\n",
    "print (scores)\n",
    "print (np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgclf.fit(matrix, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_msgs = [\n",
    "\"FreeMsg: Txt: CALL to No: 86888 & claim your reward of 3 hours talk time to use from your phone now! Subscribe6GB\", \n",
    "\"FreeMsg: Txt: claim your reward of 3 hours talk time\",\n",
    "\"Have you visited the last lecture on physics?\",\n",
    "\"Have you visited the last lecture on physics? Just buy this book and you will have all materials! Only 99$\",\n",
    "\"Only 99$\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "little_matrix = vectorizer.transform(new_msgs)\n",
    "result_new_msgs = lgclf.predict(little_matrix)\n",
    "print (result_new_msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предпоследнее не угадал:("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.828125    0.8125      0.8372093   0.8372093   0.85496183  0.828125\n",
      "  0.7704918   0.78688525  0.816       0.85271318]\n",
      "0.822422066419\n",
      "[ 0.75        0.71794872  0.71794872  0.75        0.72881356  0.71794872\n",
      "  0.69565217  0.71304348  0.71304348  0.74576271]\n",
      "0.725016155547\n",
      "[ 0.95104895  0.88888889  0.92857143  0.92857143  0.93617021  0.92086331\n",
      "  0.92086331  0.91176471  0.91428571  0.95035461]\n",
      "0.925138255865\n",
      "[ 0.96598639  0.89855072  0.91549296  0.95833333  0.93706294  0.91304348\n",
      "  0.94444444  0.92753623  0.92198582  0.95104895]\n",
      "0.933348526858\n"
     ]
    }
   ],
   "source": [
    "for params in [(2, 2), (3, 3), (1, 3), (1, 1)]:\n",
    "    vectorizer = CountVectorizer(min_df=1, ngram_range=params)\n",
    "    matrix = vectorizer.fit_transform(texts)\n",
    "    lgclf = linear_model.LogisticRegression()\n",
    "    scores = cross_val_score(lgclf, matrix, labels, cv=10, scoring='f1')\n",
    "    print (scores)\n",
    "    print (np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.68202765  0.64628821  0.63559322  0.62978723  0.66055046  0.65437788\n",
      "  0.63478261  0.61206897  0.62931034  0.66976744]\n",
      "0.645455401356\n",
      "[ 0.39361702  0.37659033  0.390625    0.3649635   0.39130435  0.37922078\n",
      "  0.37279597  0.36868687  0.37279597  0.37563452]\n",
      "0.378623430876\n",
      "[ 0.93081761  0.9068323   0.8969697   0.88622754  0.85714286  0.87116564\n",
      "  0.87116564  0.88343558  0.86390533  0.91139241]\n",
      "0.887905460889\n"
     ]
    }
   ],
   "source": [
    "for params in [(2, 2), (3, 3), (1, 3)]:\n",
    "    vectorizer = CountVectorizer(min_df=1, ngram_range=params)\n",
    "    matrix = vectorizer.fit_transform(texts)\n",
    "    nbclf = naive_bayes.MultinomialNB()\n",
    "    scores = cross_val_score(nbclf, matrix, labels, cv=10, scoring='f1')\n",
    "    print (scores)\n",
    "    print (np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.87407407  0.84210526  0.83076923  0.88888889  0.85496183  0.84615385\n",
      "  0.82170543  0.8372093   0.8372093   0.89552239]\n",
      "0.852859955417\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=1, ngram_range=(1, 1))\n",
    "matrix = vectorizer.fit_transform(texts)\n",
    "lgclf = linear_model.LogisticRegression()\n",
    "scores = cross_val_score(lgclf, matrix, labels, cv=10, scoring='f1')\n",
    "print (scores)\n",
    "print (np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5574\n",
      "5574\n"
     ]
    }
   ],
   "source": [
    "labels, texts = readfile('SMSSpamCollection.txt')\n",
    "print (len(labels))\n",
    "print (len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5574, 1569)\n",
      "[ 0.96        0.92198582  0.92307692  0.95833333  0.93055556  0.91304348\n",
      "  0.94444444  0.92753623  0.93793103  0.95104895]\n",
      "0.936795576769\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=0.001, max_df=0.999)\n",
    "matrix = vectorizer.fit_transform(texts)\n",
    "print (matrix.shape)\n",
    "lgclf = linear_model.LogisticRegression()\n",
    "scores = cross_val_score(lgclf, matrix, labels, cv=10, scoring='f1')\n",
    "print (scores)\n",
    "print (np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "качество улучшилось на $0.3\\%$ с использованием параметров $min\\_df=0.001$ и $max\\_df=0.999$ для очистки от лишних слов. параметр $stop\\_words=\\ 'english'$ только ухудшает ситуацию, так как \"нормальные\" смски часто используют такие слова, а спамные - не очень."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) кросс-валидация показывает, что качество может сильно меняться на выборке, если в ней всего $5000$ элементов.\n",
    "\n",
    "2) Усложнение модели не всегда ведет к успеху, особенно на маленьких выборках.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
